{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0319453c",
   "metadata": {},
   "source": [
    "## Optimizing case definitions\n",
    "Public health case definitions often take the form of predictive checklists, like \"if the person has 2 or more of the following 5 symptoms, then he or she is a probable case\". Case definitions can be built by hand, e.g., by using published data and expert intuition to design them from scratch, but they can also be built automatically. This notebook provides a brief overview of the latter, as enabled by the `cdo` Python package.\n",
    "\n",
    "### Checking the performance of the original predictors\n",
    "Before trying to find optimal combinations of symptoms, it's often helpful to look at the performance of each symptom individually. Let's load the test data we have in the repository and see what predictors we have to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from importlib import reload\n",
    "\n",
    "from cdo import optimizers as ops\n",
    "from cdo import metrics, tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = pd.read_csv('data/stroke_data.csv')\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc510ec7",
   "metadata": {},
   "source": [
    "Here, we have some synthetic data about a particular outcome (`stroke`) and some of its predictors (the rest of the columns). Let's see how strongly each of the individual predictors is associated with the outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8709f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = records.stroke.values\n",
    "X = records.iloc[:, records.columns != 'stroke']\n",
    "\n",
    "single_stats = pd.concat([metrics.clf_metrics(y, X[c], mod_name=c) for c in X.columns.values])\n",
    "single_stats.columns.values[0] = 'symptom'\n",
    "single_stats.sort_values('j', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32879344",
   "metadata": {},
   "source": [
    "That's a lot of numbers! Focusing on Youden's J index (`j`), though, which is a good overall measure of classification performance, shows that there are a number of strong predictors, including hyptertension (`high_bp`), high red blood cell count (`high_rbc`), and sedentary lifestyle (`sedentary`). Picking hypertension alone would have decent performance as a screening rule (sensitivity and specificity are 84% and 73%, respectively), but let's see if we can do better by looking at combinations of the predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b487f32",
   "metadata": {},
   "source": [
    "## Examining simple combinations\n",
    "The `cdo` package implements three main methods for evaluating simple combinations of symptoms (or other kinds of predictors): an integer program, a nonlinear approximation to an integer program, and a brute-force combinatorial search. Since the integer program is guaranteed to find the best solution, let's start there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20dde5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = ops.IntegerProgram()\n",
    "ip.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77c3d1b",
   "metadata": {},
   "source": [
    "Notice how easy it is to fit the optimizer--all you need to do is pass the predictors as a `pd.DataFrame` to the .fit() method, along with the outcome as an `np.array`, and it will find the (again, guaranteed optimal) solution for you. Let's see what it was by checking the `optimizer.results` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fda53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1968cefa",
   "metadata": {},
   "source": [
    "We can see that Youden's J index has moved up to 0.71 from 0.57--not bad! Relative to `high_bp`, we gained a little specificity, and we gained a ton of sensitivity, such that the new rule only has a 4% false-negative rate. What *is* the new rule, though? Since this results format is used for the other optimizers, let's take a second to see how we can use the column names of the results object to reconstruct a plain-language case definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_simple = tools.rule_df_to_str(ip.results)\n",
    "best_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872b8f7",
   "metadata": {},
   "source": [
    "Cool. So we can see that, in the `ip.results` DataFrame, `m1` is the minimum number of symptoms the person must have, and `rule1` is the collection of symptoms. The third column, `n1`, specifies the total number of symptoms under consideration in this particular combination. Each of these has a `1` at the end because, as we'll see later, some of the optimizers also let you search for compound combinations, or combinations of simple rules, and so there will be two sets of `m` values, `n` values, and `rule` strings.\n",
    "\n",
    "The other two optimizers, `NonlinearApproximation` and `FullEnumeration`, will also work for simple combinations. Let's start with the nonlinear approximation and see how it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c075785",
   "metadata": {},
   "outputs": [],
   "source": [
    "nola = ops.NonlinearApproximation()\n",
    "nola.fit(X, y)\n",
    "nola.results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a457b7ae",
   "metadata": {},
   "source": [
    "So the runtime here was super fast--less than a second!--but we can see that with a J of 0.64, the solution is not as good as the optimum found by the integer program (both are mathematically set to optimize J). This is the downside to the nonlinear approximation--the math it uses to approximate the integer program runs fast, but it's not guaranteed to be optimal (or even close).\n",
    "\n",
    "Finally, let's try the brute-force approach. As long as we don't limit the maximum number of symptoms `n` in any candidate combination, it should recover the solution from the integer program, along with many others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e25df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = ops.FullEnumeration()\n",
    "fe.fit(X, y, max_n=6, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a37ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b4386",
   "metadata": {},
   "source": [
    "There we go! Crunching through all of the potential combinations recovered the optimal solution from before, and it also got us all of the other ones (all 20,617) of them. Having the full enumeration is reassuring in that it confirms the solution from the integer program, but it also lets us do two important things:\n",
    "\n",
    "1. Visualize the distribution of metrics for all the combinations; and\n",
    "2. Pick our \"top\" combination by examining criteria other than just the metric that was optimized.\n",
    "\n",
    "Visualization is straightforward and is handled by the `FullEnumeration.plot()` function. Since we optimized `j`, let's look at the candidate combinations as points in ROC space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bec952",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f791b8ed",
   "metadata": {},
   "source": [
    "Not very exciting, but nice if you want to get a sense for how much variability there was in the combinations' performance. We can also do a panel plot that sorts the combinations by the total number of symptoms they considered (`total_n` in the `results` object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095000b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.plot(separate_n=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafca0b7",
   "metadata": {},
   "source": [
    "Again, these aren't very exciting, partly because the symptoms in our test data are synthetic and have less variability than they might if they were real, but they're still handy.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
